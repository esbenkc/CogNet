{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_msg_files(zip_path, target_dir):\n",
    "    with ZipFile(zip_path, 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        all_files = zipObj.namelist()\n",
    "        for file in all_files:\n",
    "            if file.endswith(\".json\"):\n",
    "                zipObj.extract(file, target_dir)\n",
    "\n",
    "                \n",
    "def yield_msg_files(zip_path):\n",
    "    \"\"\" Creates generator for files in zipdir \"\"\"\n",
    "    with ZipFile(zip_path, 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        all_files = zipObj.namelist()\n",
    "        for file in all_files:\n",
    "            with zipObj.open(file, \"r\") as myfile:\n",
    "                try:\n",
    "                    yield json.loads(json.load(myfile))\n",
    "                except TypeError:\n",
    "                    yield file\n",
    "\n",
    "\n",
    "def count_msg_files(zip_path):\n",
    "    \"\"\"Counts the number of conversations in zip-file\"\"\"\n",
    "    with ZipFile(zip_path, \"r\") as zipObj:\n",
    "        return len(zipObj.namelist())\n",
    "    \n",
    "\n",
    "def read_zip_file(zip_path, file_name):\n",
    "    with ZipFile(zip_path, \"r\") as zipObj:\n",
    "        with zipObj.open(file_name, \"r\") as f:\n",
    "            return json.load(f)\n",
    "                    \n",
    "def read_json(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def read_convo(file):\n",
    "    \"\"\"reads conversation json file to dict \"\"\"\n",
    "    return json.loads(read_json(file))\n",
    "\n",
    "def hash_name(name):\n",
    "    \"\"\" simplified version (no salt) \"\"\"\n",
    "    return hashlib.sha1(name.encode()).hexdigest()\n",
    "\n",
    "def create_group_id(groupchat):\n",
    "    \"\"\"creates a group id based on participant names\"\"\"\n",
    "    participant_string = \"\".join(sorted(groupchat[\"participants\"]))\n",
    "    return hash_name(participant_string)\n",
    "\n",
    "def find_most_common(participant_list):\n",
    "    \"\"\"finds most common element in list \"\"\"\n",
    "    return Counter(participant_list).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_reactions(msg, rel_list):\n",
    "    \"\"\" Appends reaction to a reaction list (preprocessing step) \"\"\"\n",
    "    if \"reactions\" in msg.keys():\n",
    "        for reaction in msg[\"reactions\"]:\n",
    "            reaction_dict = {\"from\": reaction, \n",
    "                             \"to\": msg[\"sender_name\"], \n",
    "                             \"timestamp\": msg[\"timestamp_ms\"], \n",
    "                             \"rel_type\": \"reaction\"}\n",
    "            rel_list.append(reaction_dict)\n",
    "\n",
    "            \n",
    "            \n",
    "def create_member_edges(group_convo, group_id):\n",
    "    \"\"\" Create participant --> group relations for a conversation \"\"\"\n",
    "    return pd.DataFrame({\"from\": group_convo[\"participants\"], \n",
    "                          \"to\": group_id, \n",
    "                          \"timestamp\": np.nan, \n",
    "                          \"rel_type\": \"group\"})\n",
    "\n",
    "def process_group_messages(group_convo, group_id):\n",
    "    \"\"\" Create a nice dataframe with all the messages from group chat\"\"\"\n",
    "    assert convo[\"thread_type\"] == \"RegularGroup\"\n",
    "    group_msgs = pd.DataFrame(index=range(len(group_convo[\"messages\"])), \n",
    "                              columns=[\"from\", \"to\", \"timestamp\", \"rel_type\"])\n",
    "    group_msgs = group_msgs.assign(to = group_id, rel_type = \"msg\")\n",
    "    rel_list = []\n",
    "    for i, msg in enumerate(group_convo[\"messages\"]):\n",
    "        group_msgs.loc[i, \"from\"] = msg[\"sender_name\"]\n",
    "        group_msgs.loc[i, \"timestamp\"] = msg[\"timestamp_ms\"]\n",
    "        add_reactions(msg, rel_list)\n",
    "    return pd.concat([group_msgs, pd.DataFrame(rel_list)])\n",
    "\n",
    "def process_group_edges(group_convo):\n",
    "    \"\"\" Full pipeline for processing group chats \"\"\"\n",
    "    group_id = create_group_id(group_convo)\n",
    "    group_msgs = process_group_messages(group_convo, group_id)\n",
    "    group_members = create_member_edges(group_convo, group_id)\n",
    "    return pd.concat([group_msgs, group_members]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def process_msgs(convo):\n",
    "    \"\"\" Processes messages and returns a nice dataframe :)) \"\"\"\n",
    "    if len(convo[\"participants\"]) == 1:\n",
    "        return None\n",
    "    assert convo[\"thread_type\"] == \"Regular\"\n",
    "    msgs = pd.DataFrame(index=range(len(convo[\"messages\"])), \n",
    "                        columns=[\"from\", \"to\", \"timestamp\", \"rel_type\"])\n",
    "    msgs = msgs.assign(rel_type = \"msg\")\n",
    "    rel_list = []\n",
    "    for i, msg in enumerate(convo[\"messages\"]):\n",
    "        if \"call_duration\" in msg.keys():\n",
    "            continue\n",
    "        msgs.loc[i, \"from\"] = msg[\"sender_name\"]\n",
    "        msgs.loc[i, \"to\"] = msg[\"receiver_name\"]\n",
    "        msgs.loc[i, \"timestamp\"] = msg[\"timestamp_ms\"]\n",
    "        add_reactions(msg, rel_list)\n",
    "    return pd.concat([msgs.dropna(subset=[\"from\"])\n",
    "                            , pd.DataFrame(rel_list)])\n",
    "\n",
    "\n",
    "def fix_dropout_dict(data_path):    \n",
    "    \"\"\"adds name to dropout dict as well as fixes key\"\"\"\n",
    "    participant_list = []\n",
    "    num_two_person = 0\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        for convo in yield_msg_files(data_path):\n",
    "            is_two_person = convo[\"thread_type\"] == \"Regular\"\n",
    "            if is_two_person:\n",
    "                num_two_person += 1\n",
    "                participant_list.extend(convo[\"participants\"])      \n",
    "            if num_two_person == 2:\n",
    "                stop = True\n",
    "                break\n",
    "        \n",
    "    dropout_dict = read_zip_file(data_path, \"dropout.json\")\n",
    "    dropout_dict[\"still_cogsci\"] = dropout_dict.pop(\"is_dropout\")\n",
    "    dropout_dict[\"name\"] = find_most_common(participant_list)\n",
    "    return dropout_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "data_paths = list(DATA_DIR.glob(\"*.zip\"))\n",
    "dropout_list = [None for _ in range(len(data_paths))]\n",
    "for i, data_path in enumerate(data_paths):\n",
    "    dropout_list[i] = fix_dropout_dict(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing convo 1 out of 173...\n",
      "processing convo 2 out of 173...\n",
      "processing convo 3 out of 173...\n",
      "processing convo 4 out of 173...\n",
      "processing convo 5 out of 173...\n",
      "processing convo 6 out of 173...\n",
      "processing convo 7 out of 173...\n",
      "processing convo 8 out of 173...\n",
      "processing convo 9 out of 173...\n",
      "processing convo 10 out of 173...\n",
      "processing convo 11 out of 173...\n",
      "processing convo 12 out of 173...\n",
      "processing convo 13 out of 173...\n",
      "processing convo 14 out of 173...\n",
      "processing convo 15 out of 173...\n",
      "processing convo 16 out of 173...\n",
      "processing convo 17 out of 173...\n",
      "processing convo 18 out of 173...\n",
      "processing convo 19 out of 173...\n",
      "processing convo 20 out of 173...\n",
      "processing convo 21 out of 173...\n",
      "processing convo 22 out of 173...\n",
      "processing convo 23 out of 173...\n",
      "processing convo 24 out of 173...\n",
      "processing convo 25 out of 173...\n",
      "processing convo 26 out of 173...\n",
      "processing convo 27 out of 173...\n",
      "processing convo 28 out of 173...\n",
      "processing convo 29 out of 173...\n",
      "processing convo 30 out of 173...\n",
      "processing convo 31 out of 173...\n",
      "processing convo 32 out of 173...\n",
      "processing convo 33 out of 173...\n",
      "processing convo 34 out of 173...\n",
      "processing convo 35 out of 173...\n",
      "processing convo 36 out of 173...\n",
      "processing convo 37 out of 173...\n",
      "processing convo 38 out of 173...\n",
      "processing convo 39 out of 173...\n",
      "processing convo 40 out of 173...\n",
      "processing convo 41 out of 173...\n",
      "processing convo 42 out of 173...\n",
      "processing convo 43 out of 173...\n",
      "processing convo 44 out of 173...\n",
      "processing convo 45 out of 173...\n",
      "processing convo 46 out of 173...\n",
      "processing convo 47 out of 173...\n",
      "processing convo 48 out of 173...\n",
      "processing convo 49 out of 173...\n",
      "processing convo 50 out of 173...\n",
      "processing convo 51 out of 173...\n",
      "processing convo 52 out of 173...\n",
      "processing convo 53 out of 173...\n",
      "processing convo 54 out of 173...\n",
      "processing convo 55 out of 173...\n",
      "processing convo 56 out of 173...\n",
      "processing convo 57 out of 173...\n",
      "processing convo 58 out of 173...\n",
      "processing convo 59 out of 173...\n",
      "processing convo 60 out of 173...\n",
      "processing convo 61 out of 173...\n",
      "processing convo 62 out of 173...\n",
      "processing convo 63 out of 173...\n",
      "processing convo 64 out of 173...\n",
      "processing convo 65 out of 173...\n",
      "processing convo 66 out of 173...\n",
      "processing convo 67 out of 173...\n",
      "processing convo 68 out of 173...\n",
      "processing convo 69 out of 173...\n",
      "processing convo 70 out of 173...\n",
      "processing convo 71 out of 173...\n",
      "processing convo 72 out of 173...\n",
      "processing convo 73 out of 173...\n",
      "processing convo 74 out of 173...\n",
      "processing convo 75 out of 173...\n",
      "processing convo 76 out of 173...\n",
      "processing convo 77 out of 173...\n",
      "processing convo 78 out of 173...\n",
      "processing convo 79 out of 173...\n",
      "processing convo 80 out of 173...\n",
      "processing convo 81 out of 173...\n",
      "processing convo 82 out of 173...\n",
      "processing convo 83 out of 173...\n",
      "processing convo 84 out of 173...\n",
      "processing convo 85 out of 173...\n",
      "processing convo 86 out of 173...\n",
      "processing convo 87 out of 173...\n",
      "processing convo 88 out of 173...\n",
      "processing convo 89 out of 173...\n",
      "processing convo 90 out of 173...\n",
      "processing convo 91 out of 173...\n",
      "processing convo 92 out of 173...\n",
      "processing convo 93 out of 173...\n",
      "processing convo 94 out of 173...\n",
      "processing convo 95 out of 173...\n",
      "processing convo 96 out of 173...\n",
      "processing convo 97 out of 173...\n",
      "processing convo 98 out of 173...\n",
      "processing convo 99 out of 173...\n",
      "processing convo 100 out of 173...\n",
      "processing convo 101 out of 173...\n",
      "processing convo 102 out of 173...\n",
      "processing convo 103 out of 173...\n",
      "processing convo 104 out of 173...\n",
      "processing convo 105 out of 173...\n",
      "processing convo 106 out of 173...\n",
      "processing convo 107 out of 173...\n",
      "processing convo 108 out of 173...\n",
      "processing convo 109 out of 173...\n",
      "processing convo 110 out of 173...\n",
      "processing convo 111 out of 173...\n",
      "processing convo 112 out of 173...\n",
      "processing convo 113 out of 173...\n",
      "processing convo 114 out of 173...\n",
      "Pending\n",
      "processing convo 115 out of 173...\n",
      "processing convo 116 out of 173...\n",
      "processing convo 117 out of 173...\n",
      "processing convo 118 out of 173...\n",
      "processing convo 119 out of 173...\n",
      "processing convo 120 out of 173...\n",
      "processing convo 121 out of 173...\n",
      "processing convo 122 out of 173...\n",
      "processing convo 123 out of 173...\n",
      "processing convo 124 out of 173...\n",
      "processing convo 125 out of 173...\n",
      "processing convo 126 out of 173...\n",
      "processing convo 127 out of 173...\n",
      "processing convo 128 out of 173...\n",
      "processing convo 129 out of 173...\n",
      "processing convo 130 out of 173...\n",
      "processing convo 131 out of 173...\n",
      "processing convo 132 out of 173...\n",
      "processing convo 133 out of 173...\n",
      "processing convo 134 out of 173...\n",
      "processing convo 135 out of 173...\n",
      "processing convo 136 out of 173...\n",
      "processing convo 137 out of 173...\n",
      "processing convo 138 out of 173...\n",
      "processing convo 139 out of 173...\n",
      "processing convo 140 out of 173...\n",
      "processing convo 141 out of 173...\n",
      "processing convo 142 out of 173...\n",
      "processing convo 143 out of 173...\n",
      "processing convo 144 out of 173...\n",
      "processing convo 145 out of 173...\n",
      "processing convo 146 out of 173...\n",
      "processing convo 147 out of 173...\n",
      "processing convo 148 out of 173...\n",
      "processing convo 149 out of 173...\n",
      "processing convo 150 out of 173...\n",
      "processing convo 151 out of 173...\n",
      "processing convo 152 out of 173...\n",
      "processing convo 153 out of 173...\n",
      "processing convo 154 out of 173...\n",
      "processing convo 155 out of 173...\n",
      "processing convo 156 out of 173...\n",
      "processing convo 157 out of 173...\n",
      "processing convo 158 out of 173...\n",
      "processing convo 159 out of 173...\n",
      "processing convo 160 out of 173...\n",
      "processing convo 161 out of 173...\n",
      "processing convo 162 out of 173...\n",
      "processing convo 163 out of 173...\n",
      "processing convo 164 out of 173...\n",
      "processing convo 165 out of 173...\n",
      "processing convo 166 out of 173...\n",
      "processing convo 167 out of 173...\n",
      "processing convo 168 out of 173...\n",
      "processing convo 169 out of 173...\n",
      "processing convo 170 out of 173...\n",
      "processing convo 171 out of 173...\n",
      "processing convo 172 out of 173...\n",
      "processing convo 173 out of 173...\n",
      "processing convo 174 out of 173...\n"
     ]
    }
   ],
   "source": [
    "data_path = data_paths[0]\n",
    "num_files = count_msg_files(data_path)\n",
    "df_list = []\n",
    "for i, convo in enumerate(yield_msg_files(data_path)):\n",
    "    print(f\"processing convo {i+1} out of {num_files}...\")\n",
    "    if type(convo) == str:\n",
    "        continue\n",
    "    elif convo[\"thread_type\"] == \"Regular\":\n",
    "        df_list.append(process_msgs(convo))\n",
    "    elif convo[\"thread_type\"] == \"RegularGroup\":\n",
    "        df_list.append(process_group_edges(convo))\n",
    "    else:\n",
    "        print(convo[\"thread_type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_msg_files(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b01401aca70648e91556d8666179b84ab1af68b</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>1577092657453</td>\n",
       "      <td>msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23f06d0b724d5b5ff893a269281d1a79f0bcb6b2</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>1577087169190</td>\n",
       "      <td>msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12688c448b8135515026f4d932de436b37083fae</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23f06d0b724d5b5ff893a269281d1a79f0bcb6b2</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b01401aca70648e91556d8666179b84ab1af68b</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       from  \\\n",
       "0  4b01401aca70648e91556d8666179b84ab1af68b   \n",
       "1  23f06d0b724d5b5ff893a269281d1a79f0bcb6b2   \n",
       "2  12688c448b8135515026f4d932de436b37083fae   \n",
       "3  23f06d0b724d5b5ff893a269281d1a79f0bcb6b2   \n",
       "4  4b01401aca70648e91556d8666179b84ab1af68b   \n",
       "\n",
       "                                         to      timestamp rel_type  \n",
       "0  d9fb861e9674011cd75bc0313afe1672bdd3d759  1577092657453      msg  \n",
       "1  d9fb861e9674011cd75bc0313afe1672bdd3d759  1577087169190      msg  \n",
       "2  d9fb861e9674011cd75bc0313afe1672bdd3d759            NaN    group  \n",
       "3  d9fb861e9674011cd75bc0313afe1672bdd3d759            NaN    group  \n",
       "4  d9fb861e9674011cd75bc0313afe1672bdd3d759            NaN    group  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[[\"to\", \"rel_type\"]].drop_duplicates()\n",
    "\n",
    "sus_id = \"d9fb861e9674011cd75bc0313afe1672bdd3d759\"\n",
    "\n",
    "master_df[master_df[\"to\"] == sus_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12688c448b8135515026f4d932de436b37083fae</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23f06d0b724d5b5ff893a269281d1a79f0bcb6b2</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b01401aca70648e91556d8666179b84ab1af68b</td>\n",
       "      <td>d9fb861e9674011cd75bc0313afe1672bdd3d759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>96f594c25021c24ecac85799a70c168db6a5d4b5</td>\n",
       "      <td>fb17367811aa92906f8b12e767d35744efd94978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1809bac6d0946f66ff2aca1d43a64cb451081d17</td>\n",
       "      <td>fb17367811aa92906f8b12e767d35744efd94978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>df674372f1074947d7976f02bd0f680cc16598b7</td>\n",
       "      <td>9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4b01401aca70648e91556d8666179b84ab1af68b</td>\n",
       "      <td>9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>574a35bc5bc5040d1c5c99bf9a3bff3b3318d638</td>\n",
       "      <td>9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42f809348fb5f78489f0a8e11a49129c6d127db4</td>\n",
       "      <td>9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d50e76048db1e6a0aea30d591af98cd9b789838d</td>\n",
       "      <td>9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         from  \\\n",
       "2    12688c448b8135515026f4d932de436b37083fae   \n",
       "3    23f06d0b724d5b5ff893a269281d1a79f0bcb6b2   \n",
       "4    4b01401aca70648e91556d8666179b84ab1af68b   \n",
       "127  96f594c25021c24ecac85799a70c168db6a5d4b5   \n",
       "128  1809bac6d0946f66ff2aca1d43a64cb451081d17   \n",
       "..                                        ...   \n",
       "8    df674372f1074947d7976f02bd0f680cc16598b7   \n",
       "9    4b01401aca70648e91556d8666179b84ab1af68b   \n",
       "10   574a35bc5bc5040d1c5c99bf9a3bff3b3318d638   \n",
       "11   42f809348fb5f78489f0a8e11a49129c6d127db4   \n",
       "12   d50e76048db1e6a0aea30d591af98cd9b789838d   \n",
       "\n",
       "                                           to timestamp rel_type  \n",
       "2    d9fb861e9674011cd75bc0313afe1672bdd3d759       NaN    group  \n",
       "3    d9fb861e9674011cd75bc0313afe1672bdd3d759       NaN    group  \n",
       "4    d9fb861e9674011cd75bc0313afe1672bdd3d759       NaN    group  \n",
       "127  fb17367811aa92906f8b12e767d35744efd94978       NaN    group  \n",
       "128  fb17367811aa92906f8b12e767d35744efd94978       NaN    group  \n",
       "..                                        ...       ...      ...  \n",
       "8    9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6       NaN    group  \n",
       "9    9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6       NaN    group  \n",
       "10   9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6       NaN    group  \n",
       "11   9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6       NaN    group  \n",
       "12   9ea0b6a4c29d19dfd4ba04d3c4c963c7b33c34d6       NaN    group  \n",
       "\n",
       "[511 rows x 4 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[master_df[\"timestamp\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "Name: name, dtype: bool"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_df = pd.DataFrame(dropout_list)\n",
    "dropout_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
